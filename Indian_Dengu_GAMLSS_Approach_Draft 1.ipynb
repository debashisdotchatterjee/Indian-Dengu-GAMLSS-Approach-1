{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMBGh6Q/uaUAnGZp2/jMZhV",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/debashisdotchatterjee/Indian-Dengu-GAMLSS-Approach-1/blob/main/Indian_Dengu_GAMLSS_Approach_Draft%201.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install caas-jupyter-tools"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6NQcjnZ6orRH",
        "outputId": "c210623e-9d06-4a88-f1da-36f30cbe8807"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[31mERROR: Could not find a version that satisfies the requirement caas-jupyter-tools (from versions: none)\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: No matching distribution found for caas-jupyter-tools\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================\n",
        "# Dengue India 2019–2025 (NCVBDC wide sheet): Colab-ready\n",
        "# ============================================================\n",
        "\n",
        "# ---- Setup (versions chosen for Colab stability) ----\n",
        "!pip -q install pandas==2.2.2 statsmodels==0.14.2 patsy==0.5.6 openpyxl==3.1.5\n",
        "\n",
        "import os, re, zipfile\n",
        "from pathlib import Path\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import statsmodels.api as sm\n",
        "import statsmodels.formula.api as smf\n",
        "\n",
        "plt.rcParams.update({\n",
        "    \"figure.dpi\": 120, \"savefig.dpi\": 150,\n",
        "    \"axes.grid\": True, \"grid.alpha\": 0.25,\n",
        "})\n",
        "\n",
        "# ---- Paths ----\n",
        "DATA_PATH = \"dengue_india_state_2019_2025.xlsx\"  # << set this if your path differs\n",
        "OUT_DIR   = Path(\"outputs\"); OUT_DIR.mkdir(parents=True, exist_ok=True)\n",
        "PLOTS_DIR = OUT_DIR / \"plots\"; PLOTS_DIR.mkdir(exist_ok=True)\n",
        "TABLES_DIR= OUT_DIR / \"tables\"; TABLES_DIR.mkdir(exist_ok=True)\n",
        "\n",
        "# ============================================================\n",
        "# 1) Load NCVBDC sheet (wide or long) and tidy to panel\n",
        "# ============================================================\n",
        "\n",
        "def parse_exposure_from_provisional(val):\n",
        "    \"\"\"Try to parse month count from 'Provisional_Upto' column, else default 8/12.\"\"\"\n",
        "    if pd.isna(val):\n",
        "        return 8/12\n",
        "    s = str(val).strip()\n",
        "    # Examples it might contain: 'Aug', 'August', 'Upto Aug', 'Jan-Aug', '8', '8/12'\n",
        "    month_map = {'jan':1,'january':1,'feb':2,'february':2,'mar':3,'march':3,'apr':4,'april':4,\n",
        "                 'may':5,'jun':6,'june':6,'jul':7,'july':7,'aug':8,'august':8,'sep':9,'september':9,\n",
        "                 'oct':10,'october':10,'nov':11,'november':11,'dec':12,'december':12}\n",
        "    # numeric month present?\n",
        "    mnum = re.findall(r'(?<!\\d)(\\d{1,2})(?!\\d)', s)\n",
        "    if mnum:\n",
        "        try:\n",
        "            m = int(mnum[-1])\n",
        "            if 1 <= m <= 12:\n",
        "                return m/12\n",
        "        except:\n",
        "            pass\n",
        "    # month name present?\n",
        "    tokens = re.findall(r'[A-Za-z]+', s.lower())\n",
        "    for tok in tokens:\n",
        "        if tok in month_map:\n",
        "            return month_map[tok]/12\n",
        "    # range like Jan-Aug\n",
        "    rng = re.findall(r'([A-Za-z]{3,9})\\s*[-–]\\s*([A-Za-z]{3,9})', s)\n",
        "    if rng:\n",
        "        end = rng[0][1].lower()\n",
        "        if end in month_map:\n",
        "            return month_map[end]/12\n",
        "    return 8/12\n",
        "\n",
        "def load_ncvbdc_sheet(path):\n",
        "    df = pd.read_excel(path, sheet_name=0, engine=\"openpyxl\")\n",
        "    # Normalize column names (keep originals for reference)\n",
        "    cols_lower = {c: c.lower().strip() for c in df.columns}\n",
        "    inv = {v:k for k,v in cols_lower.items()}\n",
        "\n",
        "    # Detect state column\n",
        "    state_col = None\n",
        "    for key in [\"affected states/uts\", \"state/ut\", \"state\", \"states\", \"name\"]:\n",
        "        if key in inv:\n",
        "            state_col = inv[key]; break\n",
        "    if state_col is None:\n",
        "        raise ValueError(f\"Could not find a State column. Found columns: {list(df.columns)}\")\n",
        "\n",
        "    # Provisional marker column (optional)\n",
        "    prov_col = None\n",
        "    for key in [\"provisional_upto\", \"provisional upto\", \"provisional\", \"upto\"]:\n",
        "        if key in inv:\n",
        "            prov_col = inv[key]; break\n",
        "\n",
        "    # Identify wide year columns like '2019_C','2019_D'\n",
        "    year_pat = re.compile(r'^(20\\d{2})_([CDcd])$')\n",
        "    wide_cols = []\n",
        "    for c in df.columns:\n",
        "        m = year_pat.match(str(c).strip())\n",
        "        if m:\n",
        "            wide_cols.append(c)\n",
        "\n",
        "    if wide_cols:\n",
        "        # WIDE -> LONG\n",
        "        # Keep just the needed columns\n",
        "        keep = [state_col] + ([prov_col] if prov_col else []) + wide_cols\n",
        "        w = df[keep].copy()\n",
        "        w[state_col] = w[state_col].astype(str).str.strip()\n",
        "\n",
        "        # Melt all year_* columns\n",
        "        long = w.melt(id_vars=[state_col] + ([prov_col] if prov_col else []),\n",
        "                      value_vars=wide_cols, var_name=\"year_metric\", value_name=\"value\")\n",
        "        # Split year and metric\n",
        "        ym = long[\"year_metric\"].astype(str).str.extract(r'^(20\\d{2})_([CDcd])$')\n",
        "        long[\"Year\"] = ym[0].astype(int)\n",
        "        long[\"Metric\"] = ym[1].str.upper()\n",
        "\n",
        "        # Spread back to Cases/Deaths\n",
        "        panel = long.pivot_table(index=[state_col, \"Year\"] + ([prov_col] if prov_col else []),\n",
        "                                 columns=\"Metric\", values=\"value\", aggfunc=\"first\").reset_index()\n",
        "        panel = panel.rename(columns={state_col:\"State\",\"C\":\"Cases\",\"D\":\"Deaths\"})\n",
        "        # Clean numeric (NR etc.)\n",
        "        for v in [\"Cases\",\"Deaths\"]:\n",
        "            panel[v] = pd.to_numeric(panel[v], errors=\"coerce\")\n",
        "\n",
        "        # Exposure\n",
        "        panel[\"Exposure\"] = 1.0\n",
        "        if prov_col:\n",
        "            # Only apply to 2025 if a provisional marker exists\n",
        "            sel = panel[\"Year\"].eq(2025)\n",
        "            panel.loc[sel, \"Exposure\"] = panel.loc[sel, prov_col].map(parse_exposure_from_provisional)\n",
        "            # If parser failed, default to 8/12\n",
        "            panel.loc[sel & panel[\"Exposure\"].isna(), \"Exposure\"] = 8/12\n",
        "        else:\n",
        "            panel.loc[panel[\"Year\"].eq(2025), \"Exposure\"] = 8/12\n",
        "\n",
        "        # Drop helper cols\n",
        "        if prov_col:\n",
        "            panel = panel.drop(columns=[prov_col])\n",
        "\n",
        "        # Remove any national TOTAL rows if present\n",
        "        panel[\"State_clean\"] = panel[\"State\"].str.upper().str.strip()\n",
        "        total_mask = panel[\"State_clean\"].isin([\"TOTAL\",\"INDIA TOTAL\",\"NATIONAL TOTAL\",\"NATIONAL\"])\n",
        "        panel = panel.loc[~total_mask].drop(columns=[\"State_clean\"]).reset_index(drop=True)\n",
        "\n",
        "        # Sort, lag\n",
        "        panel = panel.sort_values([\"State\",\"Year\"]).reset_index(drop=True)\n",
        "        panel[\"Cases_lag\"] = panel.groupby(\"State\")[\"Cases\"].shift(1)\n",
        "        panel[\"log_cases_lag1p\"] = np.log1p(panel[\"Cases_lag\"])\n",
        "        panel[\"log_cases_1p\"] = np.log1p(panel[\"Cases\"])\n",
        "\n",
        "        return panel\n",
        "\n",
        "    else:\n",
        "        # Already LONG – try to detect columns\n",
        "        possible = {c.lower().strip(): c for c in df.columns}\n",
        "        def pick(keys):\n",
        "            for k in keys:\n",
        "                if k in possible: return possible[k]\n",
        "            return None\n",
        "\n",
        "        ycol = pick([\"year\",\"yr\"])\n",
        "        ccol = pick([\"cases\",\"case\"])\n",
        "        dcol = pick([\"deaths\",\"death\"])\n",
        "        if not all([ycol, ccol, dcol]):\n",
        "            raise ValueError(f\"Could not auto-detect columns for long format. Found: {df.columns.tolist()}\")\n",
        "\n",
        "        panel = df.rename(columns={state_col:\"State\", ycol:\"Year\", ccol:\"Cases\", dcol:\"Deaths\"}).copy()\n",
        "        for v in [\"Cases\",\"Deaths\"]:\n",
        "            panel[v] = pd.to_numeric(panel[v], errors=\"coerce\")\n",
        "        panel[\"Year\"] = panel[\"Year\"].astype(int)\n",
        "        panel[\"Exposure\"] = np.where(panel[\"Year\"].eq(2025), 8/12, 1.0)\n",
        "        panel = panel.sort_values([\"State\",\"Year\"]).reset_index(drop=True)\n",
        "        panel[\"Cases_lag\"] = panel.groupby(\"State\")[\"Cases\"].shift(1)\n",
        "        panel[\"log_cases_lag1p\"] = np.log1p(panel[\"Cases_lag\"])\n",
        "        panel[\"log_cases_1p\"] = np.log1p(panel[\"Cases\"])\n",
        "        return panel\n",
        "\n",
        "panel = load_ncvbdc_sheet(DATA_PATH)\n",
        "print(\"Loaded tidy panel:\", panel.shape)\n",
        "display(panel.head(10))\n",
        "\n",
        "# Save cleaned panel\n",
        "panel.to_csv(TABLES_DIR / \"panel_clean.csv\", index=False)\n",
        "\n",
        "# ============================================================\n",
        "# 2) Models: Poisson for cases; Binomial for CFR (deaths|cases)\n",
        "# ============================================================\n",
        "\n",
        "# ---- Cases GLM (Poisson with offset log Exposure) ----\n",
        "cases_fit_df = panel.dropna(subset=[\"Cases\",\"log_cases_lag1p\",\"Exposure\"]).copy()\n",
        "formula_cases = \"Cases ~ C(State) + bs(Year, df=4) + log_cases_lag1p\"\n",
        "\n",
        "cases_model = smf.glm(\n",
        "    formula=formula_cases,\n",
        "    data=cases_fit_df,\n",
        "    family=sm.families.Poisson(),\n",
        "    offset=np.log(cases_fit_df[\"Exposure\"])\n",
        ").fit(cov_type=\"HC0\")\n",
        "\n",
        "print(\"\\n[Cases GLM] Summary (truncated):\")\n",
        "print(cases_model.summary().as_text()[:1500])\n",
        "\n",
        "# Predict μ_hat for all rows\n",
        "panel[\"mu_cases_hat\"] = cases_model.predict(\n",
        "    panel.assign(offset=np.log(panel[\"Exposure\"]))\n",
        ")\n",
        "\n",
        "# ---- CFR GLM (Binomial on deaths proportion with weights=Cases) ----\n",
        "cfr_df = panel.copy()\n",
        "cfr_df[\"cfr_prop\"] = np.where(cfr_df[\"Cases\"]>0, cfr_df[\"Deaths\"]/cfr_df[\"Cases\"], 0.0)\n",
        "cfr_df[\"wts\"] = cfr_df[\"Cases\"].clip(lower=0)\n",
        "\n",
        "# Use same structure; points with Cases=0 get weight 0 and don't influence fit\n",
        "formula_cfr = \"cfr_prop ~ C(State) + bs(Year, df=4) + log_cases_1p\"\n",
        "\n",
        "cfr_model = smf.glm(\n",
        "    formula=formula_cfr,\n",
        "    data=cfr_df,\n",
        "    family=sm.families.Binomial(),\n",
        "    freq_weights=cfr_df[\"wts\"]\n",
        ").fit()\n",
        "\n",
        "print(\"\\n[CFR GLM] Summary (truncated):\")\n",
        "print(cfr_model.summary().as_text()[:1500])\n",
        "\n",
        "# Predict π_hat everywhere\n",
        "panel[\"pi_hat\"] = cfr_model.predict(panel)\n",
        "panel[\"mu_deaths_hat\"] = panel[\"Cases\"] * panel[\"pi_hat\"]\n",
        "\n",
        "# ============================================================\n",
        "# 3) Plots\n",
        "# ============================================================\n",
        "def savefig(path):\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(path, bbox_inches=\"tight\")\n",
        "    plt.show()\n",
        "\n",
        "# (a) Observed vs Predicted cases\n",
        "plt.figure(figsize=(6,4))\n",
        "m = panel.dropna(subset=[\"Cases\",\"mu_cases_hat\"])\n",
        "plt.scatter(m[\"Cases\"], m[\"mu_cases_hat\"], s=16, alpha=0.6)\n",
        "lim = [0, max(m[\"Cases\"].max(), m[\"mu_cases_hat\"].max())*1.05]\n",
        "plt.plot(lim, lim, ls=\"--\", lw=1, color=\"black\")\n",
        "plt.xlabel(\"Observed cases\"); plt.ylabel(\"Predicted cases (Poisson GLM)\")\n",
        "plt.title(\"Observed vs Predicted Dengue Cases\")\n",
        "savefig(PLOTS_DIR / \"plot_cases_obs_vs_pred.png\")\n",
        "\n",
        "# (b) National totals: observed vs fitted\n",
        "nat = panel.groupby(\"Year\", as_index=False).agg(\n",
        "    obs_cases=(\"Cases\",\"sum\"),\n",
        "    fit_cases=(\"mu_cases_hat\",\"sum\")\n",
        ").sort_values(\"Year\")\n",
        "\n",
        "plt.figure(figsize=(7,4))\n",
        "plt.plot(nat[\"Year\"], nat[\"obs_cases\"], marker=\"o\", label=\"Observed\")\n",
        "plt.plot(nat[\"Year\"], nat[\"fit_cases\"], marker=\"s\", ls=\"--\", label=\"Fitted\")\n",
        "plt.title(\"National Dengue Totals by Year (Observed vs Fitted)\")\n",
        "plt.xlabel(\"Year\"); plt.ylabel(\"Total cases\"); plt.legend()\n",
        "savefig(PLOTS_DIR / \"plot_national_cases_time.png\")\n",
        "\n",
        "# (c) CFR observed vs predicted (Cases>0)\n",
        "with_cases = panel.query(\"Cases > 0\").copy()\n",
        "with_cases[\"cfr_obs\"] = with_cases[\"Deaths\"] / with_cases[\"Cases\"]\n",
        "\n",
        "plt.figure(figsize=(6,4))\n",
        "plt.scatter(with_cases[\"cfr_obs\"], with_cases[\"pi_hat\"], s=16, alpha=0.6)\n",
        "mx = max(with_cases[\"cfr_obs\"].max(), with_cases[\"pi_hat\"].max())*1.05 if len(with_cases)>0 else 1\n",
        "plt.plot([0,mx],[0,mx], ls=\"--\", lw=1, color=\"black\")\n",
        "plt.xlabel(\"Observed CFR\"); plt.ylabel(\"Predicted CFR (Binomial GLM)\")\n",
        "plt.title(\"Observed vs Predicted CFR\")\n",
        "savefig(PLOTS_DIR / \"plot_cfr_obs_vs_pred.png\")\n",
        "\n",
        "# (d) Top 15 by predicted cases in 2024 and 2025\n",
        "def top15_for_year(df, year):\n",
        "    sub = df[df[\"Year\"]==year].copy()\n",
        "    sub = sub.sort_values(\"mu_cases_hat\", ascending=False).head(15)\n",
        "    return sub\n",
        "\n",
        "top2024 = top15_for_year(panel, 2024)\n",
        "top2025 = top15_for_year(panel, 2025)\n",
        "\n",
        "# Save tables\n",
        "top2024[[\"State\",\"Cases\",\"mu_cases_hat\",\"Deaths\"]].to_csv(TABLES_DIR / \"table_top15_2024_cases.csv\", index=False)\n",
        "top2025[[\"State\",\"Cases\",\"mu_cases_hat\"]].to_csv(TABLES_DIR / \"table_top15_2025_cases.csv\", index=False)\n",
        "\n",
        "# Barh for 2025\n",
        "plt.figure(figsize=(7,6))\n",
        "order = top2025.sort_values(\"mu_cases_hat\")  # ascending for barh\n",
        "plt.barh(order[\"State\"], order[\"mu_cases_hat\"])\n",
        "plt.xlabel(\"Predicted cases (2025, exposure-adjusted)\")\n",
        "plt.title(\"Top 15 Predicted State/UT Burdens in 2025\")\n",
        "savefig(PLOTS_DIR / \"plot_top15_2025_cases_barh.png\")\n",
        "\n",
        "# ============================================================\n",
        "# 4) Save modeling outputs and LaTeX longtables\n",
        "# ============================================================\n",
        "\n",
        "# CFR ranking table\n",
        "cfr_rank = with_cases.groupby(\"State\", as_index=False).agg(\n",
        "    observed_cfr=(\"cfr_obs\",\"mean\"),\n",
        "    predicted_cfr=(\"pi_hat\",\"mean\"),\n",
        "    avg_cases=(\"Cases\",\"mean\")\n",
        ").sort_values([\"predicted_cfr\",\"observed_cfr\"], ascending=[False, False])\n",
        "cfr_rank.to_csv(TABLES_DIR / \"table_state_cfr_ranking.csv\", index=False)\n",
        "\n",
        "# Per state-year predictions\n",
        "cases_pred  = panel[[\"State\",\"Year\",\"Cases\",\"Deaths\",\"mu_cases_hat\"]].copy()\n",
        "deaths_pred = panel[[\"State\",\"Year\",\"Cases\",\"Deaths\",\"pi_hat\",\"mu_deaths_hat\"]].copy()\n",
        "cases_pred.to_csv(TABLES_DIR / \"cases_predictions.csv\", index=False)\n",
        "deaths_pred.to_csv(TABLES_DIR / \"deaths_predictions.csv\", index=False)\n",
        "panel.to_csv(TABLES_DIR / \"panel_with_predictions.csv\", index=False)\n",
        "\n",
        "# ---- LaTeX longtable writers ----\n",
        "def latex_escape(s):\n",
        "    if pd.isna(s): return \"\"\n",
        "    s = str(s)\n",
        "    repl = {'\\\\':'\\\\textbackslash{}','&':'\\\\&','%':'\\\\%','$':'\\\\$','#':'\\\\#','_':'\\\\_',\n",
        "            '{':'\\\\{','}':'\\\\}','~':'\\\\textasciitilde{}','^':'\\\\textasciicircum{}'}\n",
        "    for k,v in repl.items(): s = s.replace(k,v)\n",
        "    return s\n",
        "\n",
        "def to_longtable_tex(df, columns, headers, label, caption, align=None, float_fmt=None):\n",
        "    df2 = df.copy()\n",
        "    if float_fmt:\n",
        "        for col, fmt in float_fmt.items():\n",
        "            if col in df2.columns:\n",
        "                df2[col] = df2[col].map(lambda x: \"\" if pd.isna(x) else fmt.format(x))\n",
        "    if align is None:\n",
        "        align = \"l\" + \"r\"*(len(columns)-1)\n",
        "    lines = []\n",
        "    lines += [f\"\\\\begin{{longtable}}{{{align}}}\",\n",
        "              f\"\\\\caption{{{caption}}}\\\\\\\\\",\n",
        "              f\"\\\\label{{{label}}}\\\\\\\\\",\n",
        "              \"\\\\toprule\",\n",
        "              \" & \".join(headers) + \" \\\\\\\\\",\n",
        "              \"\\\\midrule\",\n",
        "              \"\\\\endfirsthead\",\n",
        "              \"\\\\toprule\",\n",
        "              \" & \".join(headers) + \" \\\\\\\\\",\n",
        "              \"\\\\midrule\",\n",
        "              \"\\\\endhead\",\n",
        "              \"\\\\midrule\",\n",
        "              f\"\\\\multicolumn{{{len(columns)}}}{{r}}{{\\\\emph{{Continued on next page}}}}\\\\\\\\\",\n",
        "              \"\\\\bottomrule\",\n",
        "              \"\\\\endfoot\",\n",
        "              \"\\\\bottomrule\",\n",
        "              \"\\\\endlastfoot\"]\n",
        "    for _, r in df2.iterrows():\n",
        "        row = [latex_escape(r[c]) for c in columns]\n",
        "        lines.append(\" & \".join(row) + \" \\\\\\\\\")\n",
        "    lines.append(\"\\\\end{longtable}\")\n",
        "    return \"\\n\".join(lines)\n",
        "\n",
        "# Panel longtable\n",
        "panel_cols = [\"State\",\"Year\",\"Cases\",\"mu_cases_hat\",\"Deaths\",\"pi_hat\",\"mu_deaths_hat\"]\n",
        "panel_hdrs = [\"State/UT\",\"Year\",\"Cases\",\"Pred. Cases\",\"Deaths\",\"Pred. CFR\",\"Pred. Deaths\"]\n",
        "panel_fmt  = {\"mu_cases_hat\":\"{:.1f}\",\"mu_deaths_hat\":\"{:.1f}\",\"pi_hat\":\"{:.4f}\"}\n",
        "panel_tex  = to_longtable_tex(\n",
        "    panel[panel_cols], panel_cols, panel_hdrs,\n",
        "    label=\"tab:panel-with-preds-manual\",\n",
        "    caption=\"State--year panel with observed counts and model predictions (manual longtable).\",\n",
        "    float_fmt=panel_fmt\n",
        ")\n",
        "(TABLES_DIR / \"panel_with_predictions_table.tex\").write_text(panel_tex)\n",
        "\n",
        "# Cases longtable\n",
        "cases_cols = [\"State\",\"Year\",\"Cases\",\"Deaths\",\"mu_cases_hat\"]\n",
        "cases_hdrs = [\"State/UT\",\"Year\",\"Cases\",\"Deaths\",\"Pred. Cases\"]\n",
        "cases_tex  = to_longtable_tex(\n",
        "    cases_pred[cases_cols], cases_cols, cases_hdrs,\n",
        "    label=\"tab:cases-preds-manual\",\n",
        "    caption=\"Cases model outputs by state--year (manual longtable).\",\n",
        "    float_fmt={\"mu_cases_hat\":\"{:.1f}\"}\n",
        ")\n",
        "(TABLES_DIR / \"cases_predictions_table.tex\").write_text(cases_tex)\n",
        "\n",
        "# Deaths|cases longtable\n",
        "deaths_cols = [\"State\",\"Year\",\"Cases\",\"Deaths\",\"pi_hat\",\"mu_deaths_hat\"]\n",
        "deaths_hdrs = [\"State/UT\",\"Year\",\"Cases\",\"Deaths\",\"Pred. CFR\",\"Pred. Deaths\"]\n",
        "deaths_tex  = to_longtable_tex(\n",
        "    deaths_pred[deaths_cols], deaths_cols, deaths_hdrs,\n",
        "    label=\"tab:deaths-preds-manual\",\n",
        "    caption=\"Deaths|cases model outputs (manual longtable).\",\n",
        "    float_fmt={\"pi_hat\":\"{:.6f}\",\"mu_deaths_hat\":\"{:.1f}\"}\n",
        ")\n",
        "(TABLES_DIR / \"deaths_predictions_table.tex\").write_text(deaths_tex)\n",
        "\n",
        "# ============================================================\n",
        "# 5) Show a few tables in Colab and zip everything\n",
        "# ============================================================\n",
        "print(\"\\nTop 15 by predicted cases (2024):\")\n",
        "display(top2024[[\"State\",\"Cases\",\"mu_cases_hat\",\"Deaths\"]])\n",
        "\n",
        "print(\"\\nTop 15 by predicted cases (2025):\")\n",
        "display(top2025[[\"State\",\"Cases\",\"mu_cases_hat\"]])\n",
        "\n",
        "print(\"\\nCFR ranking (head):\")\n",
        "display(cfr_rank.head(15))\n",
        "\n",
        "# ZIP\n",
        "ZIP_PATH = \"dengue_outputs_final.zip\"\n",
        "with zipfile.ZipFile(ZIP_PATH, \"w\", zipfile.ZIP_DEFLATED) as zf:\n",
        "    for p in PLOTS_DIR.glob(\"*.png\"):\n",
        "        zf.write(p, arcname=f\"plots/{p.name}\")\n",
        "    for t in TABLES_DIR.glob(\"*\"):\n",
        "        zf.write(t, arcname=f\"tables/{t.name}\")\n",
        "\n",
        "print(f\"\\nAll outputs saved to: {OUT_DIR}\")\n",
        "print(f\"ZIP archive ready: {ZIP_PATH}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "QqUgLMMPH_Yx",
        "outputId": "03412a2b-6f87-4a4b-bcbf-8af106d11d74"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded tidy panel: (257, 8)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Metric           State  Year   Cases  Deaths  Exposure  Cases_lag  \\\n",
              "0          A& N Island  2019   168.0     0.0  1.000000        NaN   \n",
              "1          A& N Island  2020    98.0     0.0  1.000000      168.0   \n",
              "2          A& N Island  2021   175.0     0.0  1.000000       98.0   \n",
              "3          A& N Island  2022  1014.0     3.0  1.000000      175.0   \n",
              "4          A& N Island  2023   846.0     0.0  1.000000     1014.0   \n",
              "5          A& N Island  2024    59.0     0.0  1.000000      846.0   \n",
              "6          A& N Island  2025   254.0     0.0  0.666667       59.0   \n",
              "7       Andhra Pradesh  2019  5286.0     0.0  1.000000        NaN   \n",
              "8       Andhra Pradesh  2020   925.0     0.0  1.000000     5286.0   \n",
              "9       Andhra Pradesh  2021  4760.0     0.0  1.000000      925.0   \n",
              "\n",
              "Metric  log_cases_lag1p  log_cases_1p  \n",
              "0                   NaN      5.129899  \n",
              "1              5.129899      4.595120  \n",
              "2              4.595120      5.170484  \n",
              "3              5.170484      6.922644  \n",
              "4              6.922644      6.741701  \n",
              "5              6.741701      4.094345  \n",
              "6              4.094345      5.541264  \n",
              "7                   NaN      8.573006  \n",
              "8              8.573006      6.830874  \n",
              "9              6.830874      8.468213  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-01e51c59-09fa-4bb9-ba9a-4dcb320f2d0a\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th>Metric</th>\n",
              "      <th>State</th>\n",
              "      <th>Year</th>\n",
              "      <th>Cases</th>\n",
              "      <th>Deaths</th>\n",
              "      <th>Exposure</th>\n",
              "      <th>Cases_lag</th>\n",
              "      <th>log_cases_lag1p</th>\n",
              "      <th>log_cases_1p</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>A&amp; N Island</td>\n",
              "      <td>2019</td>\n",
              "      <td>168.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>5.129899</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>A&amp; N Island</td>\n",
              "      <td>2020</td>\n",
              "      <td>98.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>168.0</td>\n",
              "      <td>5.129899</td>\n",
              "      <td>4.595120</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>A&amp; N Island</td>\n",
              "      <td>2021</td>\n",
              "      <td>175.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>98.0</td>\n",
              "      <td>4.595120</td>\n",
              "      <td>5.170484</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>A&amp; N Island</td>\n",
              "      <td>2022</td>\n",
              "      <td>1014.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>175.0</td>\n",
              "      <td>5.170484</td>\n",
              "      <td>6.922644</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>A&amp; N Island</td>\n",
              "      <td>2023</td>\n",
              "      <td>846.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1014.0</td>\n",
              "      <td>6.922644</td>\n",
              "      <td>6.741701</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>A&amp; N Island</td>\n",
              "      <td>2024</td>\n",
              "      <td>59.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>846.0</td>\n",
              "      <td>6.741701</td>\n",
              "      <td>4.094345</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>A&amp; N Island</td>\n",
              "      <td>2025</td>\n",
              "      <td>254.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>59.0</td>\n",
              "      <td>4.094345</td>\n",
              "      <td>5.541264</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>Andhra Pradesh</td>\n",
              "      <td>2019</td>\n",
              "      <td>5286.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>8.573006</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>Andhra Pradesh</td>\n",
              "      <td>2020</td>\n",
              "      <td>925.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>5286.0</td>\n",
              "      <td>8.573006</td>\n",
              "      <td>6.830874</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>Andhra Pradesh</td>\n",
              "      <td>2021</td>\n",
              "      <td>4760.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>925.0</td>\n",
              "      <td>6.830874</td>\n",
              "      <td>8.468213</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-01e51c59-09fa-4bb9-ba9a-4dcb320f2d0a')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-01e51c59-09fa-4bb9-ba9a-4dcb320f2d0a button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-01e51c59-09fa-4bb9-ba9a-4dcb320f2d0a');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-1f6e3717-dbf9-46bc-b0dd-484ae406d40b\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-1f6e3717-dbf9-46bc-b0dd-484ae406d40b')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-1f6e3717-dbf9-46bc-b0dd-484ae406d40b button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"print(f\\\"ZIP archive ready: {ZIP_PATH}\\\")\",\n  \"rows\": 10,\n  \"fields\": [\n    {\n      \"column\": \"State\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"Andhra Pradesh\",\n          \"A& N Island\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Year\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 2,\n        \"min\": 2019,\n        \"max\": 2025,\n        \"num_unique_values\": 7,\n        \"samples\": [\n          2019,\n          2020\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Cases\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1968.6476040391,\n        \"min\": 59.0,\n        \"max\": 5286.0,\n        \"num_unique_values\": 10,\n        \"samples\": [\n          925.0,\n          98.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Deaths\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.9486832980505138,\n        \"min\": 0.0,\n        \"max\": 3.0,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          3.0,\n          0.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Exposure\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.10540925533894599,\n        \"min\": 0.6666666666666666,\n        \"max\": 1.0,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0.6666666666666666,\n          1.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Cases_lag\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1749.7147471598253,\n        \"min\": 59.0,\n        \"max\": 5286.0,\n        \"num_unique_values\": 8,\n        \"samples\": [\n          98.0,\n          59.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"log_cases_lag1p\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.5005745206233336,\n        \"min\": 4.0943445622221,\n        \"max\": 8.57300625623545,\n        \"num_unique_values\": 8,\n        \"samples\": [\n          4.59511985013459,\n          4.0943445622221\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"log_cases_1p\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.5505385301036037,\n        \"min\": 4.0943445622221,\n        \"max\": 8.57300625623545,\n        \"num_unique_values\": 10,\n        \"samples\": [\n          6.8308742346461795,\n          4.59511985013459\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "[Cases GLM] Summary (truncated):\n",
            "                 Generalized Linear Model Regression Results                  \n",
            "==============================================================================\n",
            "Dep. Variable:                  Cases   No. Observations:                  220\n",
            "Model:                            GLM   Df Residuals:                      178\n",
            "Model Family:                 Poisson   Df Model:                           41\n",
            "Link Function:                    Log   Scale:                          1.0000\n",
            "Method:                          IRLS   Log-Likelihood:            -1.7965e+05\n",
            "Date:                Mon, 20 Oct 2025   Deviance:                   3.5735e+05\n",
            "Time:                        05:39:11   Pearson chi2:                 3.59e+05\n",
            "No. Iterations:                     9   Pseudo R-squ. (CS):              1.000\n",
            "Covariance Type:                  HC0                                         \n",
            "====================================================================================================\n",
            "                                       coef    std err          z      P>|z|      [0.025      0.975]\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Intercept                            4.8373      0.518      9.338      0.000       3.822       5.853\n",
            "C(State)[T.Andhra Pradesh]           2.4125      0.359      6.713      0.000       1.708       3.117\n",
            "C(State)[T.Arunachal Pradesh]       -1.8691      0.520     -3.593      0.000      -2.889      -0.850\n",
            "C(State)[T.Assam]        \n"
          ]
        },
        {
          "output_type": "error",
          "ename": "PatsyError",
          "evalue": "predict requires that you use a DataFrame when predicting from a model\nthat was created using the formula api.\n\nThe original error message returned by patsy is:\nError evaluating factor: NotImplementedError: some data points fall outside the outermost knots, and I'm not sure how to handle them. (Patches accepted!)\n    Cases ~ C(State) + bs(Year, df=4) + log_cases_lag1p\n                       ^^^^^^^^^^^^^^",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNotImplementedError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/patsy/compat.py\u001b[0m in \u001b[0;36mcall_and_wrap_exc\u001b[0;34m(msg, origin, f, *args, **kwargs)\u001b[0m\n\u001b[1;32m     39\u001b[0m             new_exc = PatsyError(\"%s: %s: %s\"\n\u001b[0;32m---> 40\u001b[0;31m                                  \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m                                  origin)\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/patsy/eval.py\u001b[0m in \u001b[0;36meval\u001b[0;34m(self, expr, source_name, inner_namespace)\u001b[0m\n\u001b[1;32m    178\u001b[0m         \u001b[0msteps\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mcapture\u001b[0m \u001b[0mthat\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;31m'\u001b[0m\u001b[0ms\u001b[0m \u001b[0mevaluation\u001b[0m \u001b[0menvironment\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 179\u001b[0;31m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    180\u001b[0m         \u001b[0mFor\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0meval_env\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mreference\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mdefault\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mthis\u001b[0m \u001b[0mcaptures\u001b[0m \u001b[0mthe\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<string>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/patsy/splines.py\u001b[0m in \u001b[0;36mtransform\u001b[0;34m(self, x, df, knots, degree, include_intercept, lower_bound, upper_bound)\u001b[0m\n\u001b[1;32m    272\u001b[0m             \u001b[0;34m\"degree\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"degree\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 273\u001b[0;31m             \u001b[0;31m# integer, or None\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    274\u001b[0m             \u001b[0;34m\"df\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"df\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/patsy/splines.py\u001b[0m in \u001b[0;36m_eval_bspline_basis\u001b[0;34m(x, knots, degree)\u001b[0m\n\u001b[1;32m     39\u001b[0m         raise NotImplementedError(\"some data points fall outside the \"\n\u001b[0;32m---> 40\u001b[0;31m                                   \u001b[0;34m\"outermost knots, and I'm not sure how \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m                                   \"to handle them. (Patches accepted!)\")\n",
            "\u001b[0;31mNotImplementedError\u001b[0m: some data points fall outside the outermost knots, and I'm not sure how to handle them. (Patches accepted!)",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[0;31mPatsyError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/statsmodels/base/model.py\u001b[0m in \u001b[0;36m_transform_predict_exog\u001b[0;34m(self, exog, transform)\u001b[0m\n\u001b[1;32m   1101\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1102\u001b[0;31m                 \u001b[0mexog\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdmatrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdesign_info\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexog\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"dataframe\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/patsy/highlevel.py\u001b[0m in \u001b[0;36mdmatrix\u001b[0;34m(formula_like, data, eval_env, NA_action, return_type)\u001b[0m\n\u001b[1;32m    295\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mrhs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 296\u001b[0;31m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    297\u001b[0m def dmatrices(formula_like, data={}, eval_env=0,\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/patsy/highlevel.py\u001b[0m in \u001b[0;36m_do_highlevel_design\u001b[0;34m(formula_like, data, eval_env, NA_action, return_type)\u001b[0m\n\u001b[1;32m    167\u001b[0m         return build_design_matrices(design_infos, data,\n\u001b[0;32m--> 168\u001b[0;31m                                      \u001b[0mNA_action\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNA_action\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    169\u001b[0m                                      return_type=return_type)\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/patsy/build.py\u001b[0m in \u001b[0;36mbuild_design_matrices\u001b[0;34m(design_infos, data, NA_action, return_type, dtype)\u001b[0m\n\u001b[1;32m    953\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mreturn_type\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"dataframe\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 954\u001b[0;31m         \u001b[0;32massert\u001b[0m \u001b[0mhave_pandas\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    955\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmatrix\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmatrices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/patsy/build.py\u001b[0m in \u001b[0;36m_eval_factor\u001b[0;34m(factor_info, data, NA_action)\u001b[0m\n\u001b[1;32m     67\u001b[0m         \u001b[0m_max_allowed_dim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfactor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 68\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mfactor_info\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_columns\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     69\u001b[0m             raise PatsyError(\"when evaluating factor %s, I got %s columns \"\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/patsy/eval.py\u001b[0m in \u001b[0;36meval\u001b[0;34m(self, memorize_state, data)\u001b[0m\n\u001b[1;32m    598\u001b[0m     \u001b[0;32massert\u001b[0m \u001b[0mpasses\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 599\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"foo\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"bar\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"quux\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    600\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"eval_env\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnamespace\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mlocals\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/patsy/eval.py\u001b[0m in \u001b[0;36m_eval\u001b[0;34m(self, code, memorize_state, data)\u001b[0m\n\u001b[1;32m    581\u001b[0m     \u001b[0;32massert\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0morigin\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 582\u001b[0;31m     \u001b[0;32massert\u001b[0m \u001b[0me2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0morigin\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"asdf\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    583\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/patsy/compat.py\u001b[0m in \u001b[0;36mcall_and_wrap_exc\u001b[0;34m(msg, origin, f, *args, **kwargs)\u001b[0m\n\u001b[1;32m     42\u001b[0m             \u001b[0;31m# Use 'exec' to hide this syntax from the Python 2 parser:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m             \u001b[0mexec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"raise new_exc from e\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mPatsyError\u001b[0m: Error evaluating factor: NotImplementedError: some data points fall outside the outermost knots, and I'm not sure how to handle them. (Patches accepted!)\n    Cases ~ C(State) + bs(Year, df=4) + log_cases_lag1p\n                       ^^^^^^^^^^^^^^",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mPatsyError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-2847579452.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    192\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    193\u001b[0m \u001b[0;31m# Predict μ_hat for all rows\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 194\u001b[0;31m panel[\"mu_cases_hat\"] = cases_model.predict(\n\u001b[0m\u001b[1;32m    195\u001b[0m     \u001b[0mpanel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0massign\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moffset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpanel\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Exposure\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    196\u001b[0m )\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/statsmodels/base/model.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, exog, transform, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1169\u001b[0m         \u001b[0mreturned\u001b[0m \u001b[0mprediction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1170\u001b[0m         \"\"\"\n\u001b[0;32m-> 1171\u001b[0;31m         exog, exog_index = self._transform_predict_exog(exog,\n\u001b[0m\u001b[1;32m   1172\u001b[0m                                                         transform=transform)\n\u001b[1;32m   1173\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/statsmodels/base/model.py\u001b[0m in \u001b[0;36m_transform_predict_exog\u001b[0;34m(self, exog, transform)\u001b[0m\n\u001b[1;32m   1107\u001b[0m                        \u001b[0;34m'\\n\\nThe original error message returned by patsy is:\\n'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1108\u001b[0m                        '{}'.format(str(str(exc))))\n\u001b[0;32m-> 1109\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1110\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0morig_exog_len\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexog\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_dict\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1111\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mexog_index\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mPatsyError\u001b[0m: predict requires that you use a DataFrame when predicting from a model\nthat was created using the formula api.\n\nThe original error message returned by patsy is:\nError evaluating factor: NotImplementedError: some data points fall outside the outermost knots, and I'm not sure how to handle them. (Patches accepted!)\n    Cases ~ C(State) + bs(Year, df=4) + log_cases_lag1p\n                       ^^^^^^^^^^^^^^"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd, os, re\n",
        "\n",
        "OUTDIR = \"/mnt/data/dengue_run\"\n",
        "tbl2024 = pd.read_csv(os.path.join(OUTDIR, \"table_top15_2024_cases.csv\"))\n",
        "tbl2025 = pd.read_csv(os.path.join(OUTDIR, \"table_top15_2025_cases.csv\"))\n",
        "tblcfr  = pd.read_csv(os.path.join(OUTDIR, \"table_state_cfr_ranking.csv\"))\n",
        "\n",
        "def escape_latex(s):\n",
        "    s = str(s)\n",
        "    repl = {\n",
        "        '&': r'\\&',\n",
        "        '%': r'\\%',\n",
        "        '$': r'\\$',\n",
        "        '#': r'\\#',\n",
        "        '_': r'\\_',\n",
        "        '{': r'\\{',\n",
        "        '}': r'\\}',\n",
        "        '~': r'\\textasciitilde{}',\n",
        "        '^': r'\\textasciicircum{}',\n",
        "        '\\\\': r'\\textbackslash{}',\n",
        "    }\n",
        "    for k,v in repl.items():\n",
        "        s = s.replace(k,v)\n",
        "    return s\n",
        "\n",
        "def fmt_int(x):\n",
        "    try:\n",
        "        return f\"{int(round(x))}\"\n",
        "    except:\n",
        "        return \"\"\n",
        "\n",
        "def fmt_float1(x):\n",
        "    try:\n",
        "        return f\"{x:,.1f}\"\n",
        "    except:\n",
        "        return \"\"\n",
        "\n",
        "def fmt_float4(x):\n",
        "    try:\n",
        "        return f\"{x:.4f}\"\n",
        "    except:\n",
        "        return \"\"\n",
        "\n",
        "rows_2024 = []\n",
        "for _, r in tbl2024.iterrows():\n",
        "    st = escape_latex(r['state'])\n",
        "    rows_2024.append(f\"{st} & {fmt_int(r['cases'])} & {fmt_float1(r['mu_cases_hat'])} & {fmt_int(r['deaths'])} \\\\\\\\\")\n",
        "\n",
        "rows_2025 = []\n",
        "for _, r in tbl2025.iterrows():\n",
        "    st = escape_latex(r['state'])\n",
        "    rows_2025.append(f\"{st} & {fmt_int(r['cases'])} & {fmt_float1(r['mu_cases_hat'])} \\\\\\\\\")\n",
        "\n",
        "rows_cfr = []\n",
        "for _, r in tblcfr.iterrows():\n",
        "    st = escape_latex(r['state'])\n",
        "    rows_cfr.append(f\"{st} & {fmt_float4(r['observed_cfr'])} & {fmt_float4(r['predicted_cfr'])} & {fmt_int(r['avg_cases'])} \\\\\\\\\")\n",
        "\n",
        "len(rows_2024), len(rows_2025), len(rows_cfr), rows_2025\n"
      ],
      "metadata": {
        "id": "b1SxXeySn5gX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Build manual LaTeX longtables from the CSVs and save as .tex files for \\input{}.\n",
        "import pandas as pd, numpy as np, os, re\n",
        "\n",
        "def escape_latex(s: str) -> str:\n",
        "    s = str(s)\n",
        "    repl = {\n",
        "        '\\\\': r'\\textbackslash{}',\n",
        "        '&': r'\\&', '%': r'\\%', '$': r'\\$', '#': r'\\#',\n",
        "        '_': r'\\_', '{': r'\\{', '}': r'\\}',\n",
        "        '~': r'\\textasciitilde{}', '^': r'\\textasciicircum{}',\n",
        "    }\n",
        "    for k,v in repl.items():\n",
        "        s = s.replace(k,v)\n",
        "    return s\n",
        "\n",
        "def fmt_int(x):\n",
        "    try:\n",
        "        if pd.isna(x): return ''\n",
        "        return f\"{int(round(float(x)))}\"\n",
        "    except Exception:\n",
        "        return str(x)\n",
        "\n",
        "def fmt_1(x):\n",
        "    try:\n",
        "        if pd.isna(x): return ''\n",
        "        return f\"{float(x):,.1f}\"\n",
        "    except Exception:\n",
        "        return str(x)\n",
        "\n",
        "def fmt_4(x):\n",
        "    try:\n",
        "        if pd.isna(x): return ''\n",
        "        return f\"{float(x):.4f}\"\n",
        "    except Exception:\n",
        "        return str(x)\n",
        "\n",
        "# Try preferred paths from the recent run; fallback to root if not found\n",
        "base_candidates = [\"/mnt/data/dengue_run\", \"/mnt/data\"]\n",
        "def find_csv(relname):\n",
        "    for base in base_candidates:\n",
        "        p = os.path.join(base, relname)\n",
        "        if os.path.exists(p):\n",
        "            return p\n",
        "    raise FileNotFoundError(relname)\n",
        "\n",
        "# Load CSVs\n",
        "panel_csv = find_csv(\"panel_with_predictions.csv\")\n",
        "cases_csv = find_csv(\"cases_predictions.csv\")\n",
        "deaths_csv= find_csv(\"deaths_predictions.csv\")\n",
        "\n",
        "panel = pd.read_csv(panel_csv)\n",
        "cases = pd.read_csv(cases_csv)\n",
        "deaths= pd.read_csv(deaths_csv)\n",
        "\n",
        "# Subset columns for panel\n",
        "panel_cols = []\n",
        "for c in [\"state\",\"year\",\"cases\",\"mu_cases_hat\",\"deaths\",\"pi_hat\",\"mu_deaths_hat\"]:\n",
        "    if c in panel.columns:\n",
        "        panel_cols.append(c)\n",
        "panel_sub = panel[panel_cols].copy()\n",
        "\n",
        "# Formatting functions map\n",
        "fmt_map = {\n",
        "    \"state\": escape_latex,\n",
        "    \"year\": fmt_int,\n",
        "    \"cases\": fmt_int,\n",
        "    \"deaths\": fmt_int,\n",
        "    \"mu_cases_hat\": fmt_1,\n",
        "    \"mu_deaths_hat\": fmt_1,\n",
        "    \"pi_hat\": fmt_4,\n",
        "}\n",
        "\n",
        "def df_to_longtable(df: pd.DataFrame, col_order, col_headers, fmts, label, caption):\n",
        "    # Build header\n",
        "    colspec = \"l\" + \"r\"*(len(col_order)-1)\n",
        "    lines = []\n",
        "    lines.append(\"\\\\begin{longtable}{\" + colspec + \"}\")\n",
        "    lines.append(\"\\\\caption{\" + caption + \"}\\\\\\\\\")\n",
        "    lines.append(\"\\\\label{\" + label + \"}\\\\\\\\\")\n",
        "    lines.append(\"\\\\toprule\")\n",
        "    lines.append(\" & \".join(col_headers) + \" \\\\\\\\\")\n",
        "    lines.append(\"\\\\midrule\")\n",
        "    lines.append(\"\\\\endfirsthead\")\n",
        "    lines.append(\"\\\\toprule\")\n",
        "    lines.append(\" & \".join(col_headers) + \" \\\\\\\\\")\n",
        "    lines.append(\"\\\\midrule\")\n",
        "    lines.append(\"\\\\endhead\")\n",
        "    lines.append(\"\\\\midrule\")\n",
        "    lines.append(\"\\\\multicolumn{\" + str(len(col_order)) + \"}{r}{\\\\emph{Continued on next page}}\\\\\\\\\")\n",
        "    lines.append(\"\\\\bottomrule\")\n",
        "    lines.append(\"\\\\endfoot\")\n",
        "    lines.append(\"\\\\bottomrule\")\n",
        "    lines.append(\"\\\\endlastfoot\")\n",
        "    # Rows\n",
        "    for _, r in df.iterrows():\n",
        "        vals = []\n",
        "        for c in col_order:\n",
        "            v = r.get(c, \"\")\n",
        "            fmt = fmts.get(c, escape_latex)\n",
        "            vals.append(fmt(v))\n",
        "        lines.append(\" & \".join(vals) + \" \\\\\\\\\")\n",
        "    lines.append(\"\\\\end{longtable}\")\n",
        "    return \"\\n\".join(lines)\n",
        "\n",
        "# Ensure output dir\n",
        "outdir = \"/mnt/data/latex_tables\"\n",
        "os.makedirs(outdir, exist_ok=True)\n",
        "\n",
        "# 1) panel_with_predictions_table.tex\n",
        "panel_order = panel_cols\n",
        "panel_headers = [\"State/UT\",\"Year\",\"Cases\",\"Pred. Cases\",\"Deaths\",\"Pred. CFR\",\"Pred. Deaths\"]\n",
        "panel_tex = df_to_longtable(panel_sub, panel_order, panel_headers, fmt_map,\n",
        "                            \"tab:panel-with-preds-manual\",\n",
        "                            \"State--year panel with observed counts and model predictions (manual longtable).\")\n",
        "with open(os.path.join(outdir, \"panel_with_predictions_table.tex\"), \"w\") as f:\n",
        "    f.write(panel_tex)\n",
        "\n",
        "# 2) cases_predictions_table.tex\n",
        "cases_cols = []\n",
        "for c in [\"state\",\"year\",\"cases\",\"deaths\",\"mu_cases_hat\"]:\n",
        "    if c in cases.columns:\n",
        "        cases_cols.append(c)\n",
        "cases_headers = [\"State/UT\",\"Year\",\"Cases\",\"Deaths\",\"Pred. Cases\"]\n",
        "cases_tex = df_to_longtable(cases[cases_cols], cases_cols, cases_headers, fmt_map,\n",
        "                            \"tab:cases-preds-manual\",\n",
        "                            \"Cases model outputs by state--year (manual longtable).\")\n",
        "with open(os.path.join(outdir, \"cases_predictions_table.tex\"), \"w\") as f:\n",
        "    f.write(cases_tex)\n",
        "\n",
        "# 3) deaths_predictions_table.tex\n",
        "deaths_cols = []\n",
        "for c in [\"state\",\"year\",\"cases\",\"deaths\",\"pi_hat\",\"mu_deaths_hat\"]:\n",
        "    if c in deaths.columns:\n",
        "        deaths_cols.append(c)\n",
        "deaths_headers = [\"State/UT\",\"Year\",\"Cases\",\"Deaths\",\"Pred. CFR\",\"Pred. Deaths\"]\n",
        "deaths_tex = df_to_longtable(deaths[deaths_cols], deaths_cols, deaths_headers, fmt_map,\n",
        "                             \"tab:deaths-preds-manual\",\n",
        "                             \"Deaths|cases model outputs (manual longtable).\")\n",
        "with open(os.path.join(outdir, \"deaths_predictions_table.tex\"), \"w\") as f:\n",
        "    f.write(deaths_tex)\n",
        "\n",
        "# Return paths for user to \\input or download\n",
        "[outdir + \"/panel_with_predictions_table.tex\",\n",
        " outdir + \"/cases_predictions_table.tex\",\n",
        " outdir + \"/deaths_predictions_table.tex\"]\n"
      ],
      "metadata": {
        "id": "Rub-83SBn0zh"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}